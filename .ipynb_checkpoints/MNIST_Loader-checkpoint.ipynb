{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader for MNIST Database\n",
    "\n",
    "This tutorial shows you how to download the MNIST digit database and process it to make it ready for machine learning algorithms.\n",
    "\n",
    "## Topics to be covered\n",
    "\n",
    "1. Downloading the dataset.\n",
    "2. Processing the raw data to a easier data structure (numpy ndarray).\n",
    "3. Saving the images.\n",
    "4. Saving the dataset as a pickle file\n",
    "\n",
    "\n",
    "## Downloading the Dataset\n",
    "\n",
    "The dataset can be downloaded using a browser using the following downloadable links :\n",
    "\n",
    "* [Training Images](http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz)\n",
    "* [Training Labels](http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz)\n",
    "* [Testing Images](http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz)\n",
    "* [Testing Labels](http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz)\n",
    "\n",
    "Alternatively the code segment below can also be used to download the images to a specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import os,urllib.request\n",
    "\n",
    "\n",
    "# PROVIDE YOUR DOWNLOAD DIRECTORY HERE\n",
    "datapath = '../../Data/MNISTData/'  \n",
    "\n",
    "# CREATING DOWNLOAD DIRECTORY\n",
    "if not os.path.exists(datapath):\n",
    "    os.makedirs(datapath)\n",
    "\n",
    "# URLS TO DOWNLOAD FROM\n",
    "urls = ['http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
    "       'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
    "       'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "       'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz']\n",
    "\n",
    "for url in urls:\n",
    "    filename = url.split('/')[-1]   # GET FILENAME\n",
    "    \n",
    "    if os.path.exists(datapath+filename):\n",
    "        print(filename, ' already exists')  # CHECK IF FILE EXISTS\n",
    "    else:\n",
    "        print('Downloading ',filename)\n",
    "        urllib.request.urlretrieve (url, datapath+filename) # DOWNLOAD FILE\n",
    "     \n",
    "print('All files are available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the downloaded files\n",
    "\n",
    "The downloaded files are in an archive format and needs to be extracted. It can be manually extracted using the GUI or the code segment below can also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,gzip,shutil\n",
    "\n",
    "# PROVIDE YOUR DOWNLOAD DIRECTORY HERE\n",
    "datapath = '../../Data/MNISTData/'  \n",
    "\n",
    "# LISTING ALL ARCHIVES IN THE DIRECTORY\n",
    "files = os.listdir(datapath)\n",
    "for file in files:\n",
    "    if file.endswith('gz'):\n",
    "        print('Extracting ',file)\n",
    "        with gzip.open(datapath+file, 'rb') as f_in:\n",
    "            with open(datapath+file.split('.')[0], 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "print('Extraction Complete')\n",
    "\n",
    "# OPTIONAL REMOVE THE ARCHIVES\n",
    "for file in files:\n",
    "    print('Removing ',file)\n",
    "    os.remove(datapath+file)\n",
    "print ('All archives removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "  table {margin-left: 0 !important;}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "  table {margin-left: 0 !important;}\n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the Files \n",
    "All the image files and labels of the MNIST dataset is encoded into these 4 files. We need to be able to extract the images from the files to work with them.\n",
    "\n",
    "### File descriptions\n",
    "Four files are provided:\n",
    "\n",
    "* Test Images : t10k-images-idx3-ubyte\n",
    "* Test Labels :  t10k-labels-idx1-ubyte\n",
    "* Train Images : train-images-idx3-ubyte\n",
    "* Train Labels :  train-labels-idx1-ubyte\n",
    "\n",
    "The IDX file format is a simple format for vectors and multidimensional matrices of various numerical types.\n",
    "\n",
    "#### The basic format for labels\n",
    "  \n",
    "|Offset | Type               | Value           |   Description                   |\n",
    "|-------|--------------------|-----------------|---------------------------------|\n",
    "|0000   |4 byte integer      |0x00000801(2049) |magic number (MSB first)         |\n",
    "|0004   |4 byte integer      |10000 or 60000   |number of items (test or train)  |\n",
    "|0008   |unsigned byte       |??               |label                            |\n",
    "|0009   |unsigned byte       |??               |label                            |\n",
    "|...    |...                 |...              |...                              |\n",
    "|xxxx   |unsigned byte       |??               |label                            |\n",
    "\n",
    "\n",
    "#### The basic format for images\n",
    "\n",
    "|Offset | Type               | Value           |   Description                   |\n",
    "|-------|--------------------|-----------------|---------------------------------|\n",
    "|0000   |4 byte integer      |0x00000801(2051) |magic number (MSB first)         |\n",
    "|0004   |4 byte integer      |10000 or 60000   |number of images (test or train) |\n",
    "|0008   |4 byte integer      |28               |number of rows                   |\n",
    "|0012   |4 byte integer      |28               |number of columns                |\n",
    "|0016   |unsigned byte       |??               |pixel intensity (0-255)          |\n",
    "|0017   |unsigned byte       |??               |pixel intensity (0-255)          |\n",
    "|...    |...                 |...              |...                              |\n",
    "|xxxx   |unsigned byte       |??               |pixel intensity (0-255)          |\n",
    "\n",
    "\n",
    "### Converting the ubyte files to numpy arrays for easy processing\n",
    "The following code converts the ubyte files into four numpy n dimensional arrays and stores them in a dictionary called `data_dict` which has four key, value pairs.\n",
    "\n",
    "| Key           |  Type        |Shape         |\n",
    "|---------------|--------------|--------------|\n",
    "|*train_images* |numpy ndarray |[60000,28,28] |\n",
    "|*train_labels* |numpy ndarray |[60000]       |\n",
    "|*test_images*  |numpy ndarray |[10000,28,28] |\n",
    "|*test_labels*  |numpy ndarray |[10000]       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,codecs,numpy\n",
    "\n",
    "# PROVIDE YOUR DIRECTORY WITH THE EXTRACTED FILES HERE\n",
    "datapath = '../../Data/MNISTData/'\n",
    "\n",
    "files = os.listdir(datapath)\n",
    "\n",
    "def get_int(b):   # CONVERTS 4 BYTES TO A INT\n",
    "    return int(codecs.encode(b, 'hex'), 16)\n",
    "\n",
    "data_dict = {}\n",
    "for file in files:\n",
    "    if file.endswith('ubyte'):  # FOR ALL 'ubyte' FILES\n",
    "        print('Reading ',file)\n",
    "        with open (datapath+file,'rb') as f:\n",
    "            data = f.read()\n",
    "            type = get_int(data[:4])   # 0-3: THE MAGIC NUMBER TO WHETHER IMAGE OR LABEL\n",
    "            length = get_int(data[4:8])  # 4-7: LENGTH OF THE ARRAY  (DIMENSION 0)\n",
    "            if (type == 2051):\n",
    "                category = 'images'\n",
    "                num_rows = get_int(data[8:12])  # NUMBER OF ROWS  (DIMENSION 1)\n",
    "                num_cols = get_int(data[12:16])  # NUMBER OF COLUMNS  (DIMENSION 2)\n",
    "                parsed = numpy.frombuffer(data,dtype = numpy.uint8, offset = 16)  # READ THE PIXEL VALUES AS INTEGERS\n",
    "                parsed = parsed.reshape(length,num_rows,num_cols)  # RESHAPE THE ARRAY AS [NO_OF_SAMPLES x HEIGHT x WIDTH]           \n",
    "            elif(type == 2049):\n",
    "                category = 'labels'\n",
    "                parsed = numpy.frombuffer(data, dtype=numpy.uint8, offset=8) # READ THE LABEL VALUES AS INTEGERS\n",
    "                parsed = parsed.reshape(length)  # RESHAPE THE ARRAY AS [NO_OF_SAMPLES]                           \n",
    "            if (length==10000):\n",
    "                set = 'test'\n",
    "            elif (length==60000):\n",
    "                set = 'train'\n",
    "            data_dict[set+'_'+category] = parsed  # SAVE THE NUMPY ARRAY TO A CORRESPONDING KEY     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Saving images from the dataset\n",
    "\n",
    "This code segment can be used to save the data of the numpy array as images in class specific directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage.io import imsave\n",
    "datapath = '../../Data/MNISTData/' # PATH WHERE IMAGES WILL BE SAVED\n",
    "\n",
    "sets = ['train','test']\n",
    "\n",
    "for set in sets:   # FOR TRAIN AND TEST SET\n",
    "    images = data_dict[set+'_images']   # IMAGES\n",
    "    labels = data_dict[set+'_labels']   # LABELS\n",
    "    no_of_samples = images.shape[0]     # NUBMER OF SAMPLES\n",
    "    for indx in range (no_of_samples):  # FOR EVERY SAMPLE\n",
    "        print(set, indx)\n",
    "        image = images[indx]            # GET IMAGE\n",
    "        label = labels[indx]            # GET LABEL\n",
    "        if not os.path.exists(datapath+set+'/'+str(label)+'/'):    # IF DIRECTORIES DO NOT EXIST THEN \n",
    "            os.makedirs (datapath+set+'/'+str(label)+'/')       # CREATE TRAIN/TEST DIRECTORY AND CLASS SPECIFIC SUBDIRECTORY\n",
    "        filenumber = len(os.listdir(datapath+set+'/'+str(label)+'/'))  # NUMBER OF FILES IN THE DIRECTORY FOR NAMING THE FILE\n",
    "        imsave(datapath+set+'/'+str(label)+'/%05d.png'%(filenumber),image)  # SAVE THE IMAGE WITH PROPER NAME\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the dictionary using pickle\n",
    "\n",
    "Python data structures can be directly saved as it is using the pickle package.\n",
    "The code segment below shows how to save the `data_dict` using `pickle.dump` and later loading it back using `pickle.load`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "datapath = '../../Data/MNISTData/'\n",
    "\n",
    "# DUMPING THE DICTIONARY INTO A PICKLE \n",
    "with open(datapath+'MNISTData.pkl', 'wb') as fp :\n",
    "    pickle.dump(data_dict, fp)\n",
    "\n",
    "# LOADING THE DICTIONARY FROM A PICKLE\n",
    "with open(datapath+'MNISTData.pkl', 'rb') as fp :\n",
    "    new_dict = pickle.load(fp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
