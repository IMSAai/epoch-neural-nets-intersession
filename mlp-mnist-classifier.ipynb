{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "**Number classifier on MNIST dataset using linear neurons**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets # get the MNIST dataset\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np # view images\n",
    "import matplotlib.pyplot as plt # allows us to plot the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20 # how many samples in each batch of the data\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {}\".format(device))\n",
    "# convert data to a PyTorch tensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "\n",
    "# prepare data loaders, which download the dataset to train on\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# command for python notebooks\n",
    "\n",
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20): # get 20 images\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray') # add the black and white images\n",
    "    # print out the correct label for each image\n",
    "    # .item() gets the value contained in a Tensor\n",
    "    ax.set_title(str(labels[idx].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "## Define the NN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Dropout(p=0.2), # to prevent overfitting (imagine doing the same math practice problem over and over, and thinking you know the concept well.)\n",
    "            nn.Linear(512, 10) # the number of output layers need to be the number of possible classifications that there are. The model will output the probability that each is the correct answer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 28 * 28).to(device)\n",
    "        # run through model\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "# initialize the NN\n",
    "model = Net()\n",
    "model = model.to(device)\n",
    "print(model) # see the model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # error function to use for optimization\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # use gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epochs to train the model\n",
    "epochs = 15\n",
    "\n",
    "model.train() # prep model for training (PyTorch handles things like weight init, dropout, etc.)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    for data, target in train_loader:\n",
    "        target = target.to(device)\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward prop: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data).to(device)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # backprop: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single gradient descent step\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # print training statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss\n",
    "        ))\n",
    "\n"
   ]
  },
  {
   "source": [
    "Now that our model has been trained, let's see what it can do!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain one batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "# perform prediction\n",
    "output = model(images).to(device)\n",
    "# convert output probabilities to predicted class\n",
    "_, preds = torch.max(output, 1)\n",
    "# prep images for display\n",
    "images = images.cpu().numpy()\n",
    "\n",
    "# plot the images in the batch, along with predicted and true labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(\"{} (correct is {})\".format(str(preds[idx].item()), str(labels[idx].item())),\n",
    "                 color=(\"green\" if preds[idx]==labels[idx] else \"red\")) # if the prediction is correct, set the label green, otherwise, set it to be red"
   ]
  }
 ]
}